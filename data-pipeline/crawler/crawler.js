// crawler.js
import "dotenv/config";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { initBrowser } from "./utils/browser.js";
import { BADGES, STOP_KEYWORDS, AUTH_FILE } from "./constants.js";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const GROUP_URL = process.env.FACEBOOK_GROUP_URL;

/**
 * Main crawler function.
 */
async function runCrawler() {
  if (!fs.existsSync(AUTH_FILE)) {
    console.error(
      `‚ùå ${AUTH_FILE} not found. Please run 'node auth.js' first!`,
    );
    return;
  }

  if (!GROUP_URL) {
    console.error("‚ùå FACEBOOK_GROUP_URL not found in .env file.");
    return;
  }

  const { browser, context } = await initBrowser({
    headless: false,
    useAuth: true,
  });

  const page = await context.newPage();

  console.log(`üöÄ Accessing group: ${GROUP_URL}`);

  try {
    await page.goto(GROUP_URL, {
      waitUntil: "domcontentloaded",
      timeout: 60000,
    });
  } catch (e) {
    console.log("‚ö†Ô∏è Page load timeout, continuing...");
  }

  try {
    console.log("‚è≥ Waiting for group content...");
    await page.waitForSelector('div[role="feed"]', { timeout: 20000 });
  } catch (error) {
    console.error("‚ùå Error: Group content not found.");
    await browser.close();
    return;
  }

  console.log("‚¨áÔ∏è  Scrolling page...");
  for (let i = 0; i < 3; i++) {
    try {
      await page.keyboard.press("End");
      // D√πng setTimeout thay cho waitForTimeout (ƒë√£ b·ªã deprecated)
      await new Promise((r) => setTimeout(r, 3000));
    } catch (e) {
      // Ignore scroll errors
    }
  }

  console.log("üîç Extracting and cleaning posts...");
  const posts = await page.evaluate(
    ({ badges, stopWords }) => {
      const data = [];
      const feed = document.querySelector('div[role="feed"]');
      if (!feed) return [];

      const items = Array.from(feed.children);

      items.forEach((item, index) => {
        const rawText = item.innerText;
        if (!rawText || rawText.length < 30) return;

        // --- B·∫ÆT ƒê·∫¶U LOGIC M·ªöI: T√åM LINK V√Ä NG√ÄY ƒêƒÇNG ---
        let postLink = "";
        let postDate = "";

        // 1. L·∫•y t·∫•t c·∫£ th·∫ª a trong b√†i vi·∫øt
        const allLinks = Array.from(item.querySelectorAll("a"));

        // 2. T√¨m th·∫ª a CH√çNH X√ÅC l√† ng√†y ƒëƒÉng b√†i vi·∫øt
        // ƒêi·ªÅu ki·ªán:
        // - href ch·ª©a "/posts/" ho·∫∑c "/permalink/"
        // - QUAN TR·ªåNG: KH√îNG ch·ª©a "comment_id" (ƒë·ªÉ tr√°nh l·∫•y nh·∫ßm ng√†y c·ªßa comment)
        // - QUAN TR·ªåNG: KH√îNG ch·ª©a "/user/" (ƒë·ªÉ tr√°nh l·∫•y nh·∫ßm link t√°c gi·∫£)
        const dateAnchor = allLinks.find((a) => {
          const href = a.getAttribute("href");
          if (!href) return false;

          const isPostLink =
            href.includes("/posts/") || href.includes("/permalink/");
          const isNotComment =
            !href.includes("comment_id") && !href.includes("reply_comment_id");
          const isNotUser = !href.includes("/user/");

          return isPostLink && isNotComment && isNotUser;
        });

        if (dateAnchor) {
          // X·ª≠ l√Ω Link: C·∫Øt b·ªè c√°c tham s·ªë r√°c sau d·∫•u ?
          try {
            const urlObj = new URL(dateAnchor.href);
            postLink = urlObj.origin + urlObj.pathname;
          } catch (e) {
            postLink = dateAnchor.href;
          }

          // X·ª≠ l√Ω Ng√†y ƒëƒÉng:
          // ∆Øu ti√™n 1: L·∫•y aria-label (Th∆∞·ªùng ch·ª©a: "Th·ª© Hai, 17 th√°ng 2...")
          // ∆Øu ti√™n 2: L·∫•y innerText (Th∆∞·ªùng ch·ª©a: "2 gi·ªù", "V·ª´a xong")
          // ƒê√¥i khi aria-label n·∫±m ·ªü th·∫ª span con b√™n trong th·∫ª a
          const ariaLabel =
            dateAnchor.getAttribute("aria-label") ||
            dateAnchor.querySelector("span")?.getAttribute("aria-label");

          if (ariaLabel) {
            postDate = ariaLabel;
          } else {
            postDate = dateAnchor.innerText;
          }
        }
        // ----------------------------------------------------

        // 1. Split text into lines
        let lines = rawText
          .split("\n")
          .map((l) => l.trim())
          .filter((l) => l.length > 1)
          .filter((l) => l !== "Facebook");

        if (lines.length < 2) return;

        // 2. Extract author (usually the first line)
        // Logic ph·ª•: B·ªè qua d√≤ng t√™n Group n·∫øu n√≥ xu·∫•t hi·ªán ƒë·∫ßu ti√™n (VD: UTE - ...)
        if (lines[0].startsWith("UTE -") || lines[0].includes("Nh√≥m")) {
          lines.shift();
        }
        const author = lines[0];

        // 3. Find cut-off point for main content
        let endIndex = lines.length;

        for (let i = 1; i < lines.length; i++) {
          const line = lines[i];

          // Regex for stats or common stopping keywords
          if (
            /^\d+([.,]\d+)?([KkMm])?$/.test(line) ||
            /^\d+.*(b√¨nh lu·∫≠n|l∆∞·ª£t chia s·∫ª|l∆∞·ª£t th√≠ch)/.test(line) || // Th√™m "l∆∞·ª£t th√≠ch"
            line === "Th√≠ch" ||
            line === "B√¨nh lu·∫≠n" ||
            line === "Chia s·∫ª" // Th√™m n√∫t h√†nh ƒë·ªông
          ) {
            endIndex = i;
            break;
          }

          if (stopWords.some((sw) => line.includes(sw))) {
            endIndex = i;
            break;
          }
        }

        // 4. Extract content body
        let contentLines = lines.slice(1, endIndex);

        // 5. Filter out badges and redundant group name
        contentLines = contentLines.filter(
          (line) =>
            !badges.includes(line) &&
            line !== author &&
            line !== postDate && // L·ªçc b·ªè d√≤ng ng√†y th√°ng n·∫øu tr√πng
            !line.startsWith("UTE - "),
        );

        const cleanContent = contentLines.join("\n");

        if (cleanContent.length < 5) return;

        // 6. Extract reactions and comments count
        let reactions = "0";
        let comments = "0";

        // C·∫≠p nh·∫≠t Regex ƒë·ªÉ b·∫Øt t·ªët h∆°n
        const reactMatch =
          rawText.match(/T·∫•t c·∫£ c·∫£m x√∫c:[\s\n]*(\d+[.,\dKkMm]*)/) ||
          rawText.match(/v√†[\s\n]*(\d+[.,\dKkMm]*)[\s\n]*ng∆∞·ªùi kh√°c/);

        if (reactMatch) reactions = reactMatch[1];
        else if (rawText.includes("T·∫•t c·∫£ c·∫£m x√∫c")) reactions = "Few";

        const commentMatch = rawText.match(/(\d+[.,\dKkMm]*)[\s\n]*b√¨nh lu·∫≠n/i);
        if (commentMatch) comments = commentMatch[1];

        data.push({
          id: index,
          author,
          post_date: postDate, // D·ªØ li·ªáu m·ªõi
          post_link: postLink, // D·ªØ li·ªáu m·ªõi
          content: cleanContent,
          stats: { reactions, comments },
          crawled_at: new Date().toISOString(),
        });
      });

      return data;
    },
    { badges: BADGES, stopWords: STOP_KEYWORDS },
  );

  console.log(`‚úÖ Successfully collected ${posts.length} cleaned posts.`);

  if (posts.length > 0) {
    const outputDir = path.join(__dirname, "output");
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir);
    }

    const fileName = `posts_${Date.now()}.json`;
    const filePath = path.join(outputDir, fileName);

    fs.writeFileSync(filePath, JSON.stringify(posts, null, 2));
    console.log(`üíæ Data saved to: ${filePath}`);

    // Preview first post
    console.log("üîç Sample post:", JSON.stringify(posts[0], null, 2));
  } else {
    console.log("‚ö†Ô∏è No valid posts found.");
  }

  await browser.close();
}

if (process.argv[1] === __filename) {
  runCrawler().catch((err) => {
    console.error("‚ùå Error during crawling:", err);
    process.exit(1);
  });
}
